\documentclass[../main.tex]{subfiles}
\begin{document}
\newpage
\section{Приближенное решение задачи синтеза управления на малом интервале времени}
\subsection{Асимптотика множеств достижимости нелинейных систем с интегральными ограничениями, в том числе по части координат} 
Данный раздел содержит материалы, опубликованные в статье И. О. Осипов, “О выпуклости множеств достижимости по части координат нелинейных управляемых систем на малых промежутках времени”, Вестн. Удмуртск. ун-та. Матем. Мех. Компьют. науки, 31:2 (2021),  210–225. В разделе исследована выпуклость множеств достижимости по части координат нелинейных систем с интегральными ограничениями на управление на малых промежутках времени.
Доказаны достаточные условия выпуклости, имеющие вид ограничений на асимптотику собственных чисел грамиана управляемости линеаризованной системы по части координат.
В качестве примеров, в статье описаны две нелинейные системы третьего порядка, в одной из которых линеаризованная вдоль траектории, порожденной нулевым управлением, система неуправляема, а в другом управляема.
Исследованы достаточные условия выпуклости проекций множеств достижимости. 
Проведено численное моделирование, продемонстрировавшее невыпуклость некоторых проекций даже для малых длин временного промежутка.
\subsubsection{Расстояние Банаха-Мазура и асимптотическая эквивалентность множеств}
Напомним, что расстоянием Банаха-Мазура между выпуклыми компактными множествами $ X,Y \subset \mathbb R^n $ называют величину $ \rho (X, Y)  $, определенную равенством 
\begin{gather*}
	\rho (X, Y): = \log (r(X,Y) \cdot r(Y, X)),
\end{gather*}
где $r(X, Y) = \inf \{t \geq 1: tX \supset Y \}$.\\
Пусть $ X = X(\varepsilon) $,  $ Y = Y(\varepsilon) $ -- выпуклые компактные множества, такие, что $ 0 \in \rm{int}\,X(\varepsilon) $, $ 0 \in \rm{int}\,Y(\varepsilon) $ при $0 \leqslant \varepsilon \leqslant \overline{\varepsilon} $.  Тогда, следуя \footnote{Goncharova E., Ovseevich A. Small-time reachable sets of linear systems with integral control constraints: birth of the shape of a reachable set// Journal of Optimization Theory and Applications. 2016. 168 (2). P. 615--624.
	doi: 10.1007/s10957-015-0754-4}, назовем множества $  X(\varepsilon)  $ и $  Y(\varepsilon) $ {\textit асимптотически эквивалентными}, если $  \rho (X(\varepsilon), Y(\varepsilon)) \rightarrow 0 $ при $\varepsilon \rightarrow 0 $.

Приведем далее достаточное условие асимптотической эквивалентности, выраженное через хаусдорфово расстояние $ h $ между ними.
\begin{theorem}\label{suff}\footnote{Gusev M.I. The limits of applicability of the linearization method in calculating small-time reachable sets // Ural Mathematical Journal. 2020. Vol. 6, No. 1. P. 71-83 https://doi.org/10.15826/umj.2020.1.006}
	 Выполнения следующих условий достаточно для того, чтобы множества $ X(\varepsilon) $ и $ Y(\varepsilon) $ были асимптотически эквивалентны:
	\begin{gather*}
		\lim\limits_{\varepsilon \rightarrow 0}h(X(\varepsilon),Y(\varepsilon)) = 0, \qquad	\lim\limits_{\varepsilon \rightarrow 0}\frac{h(X(\varepsilon),Y(\varepsilon))}{\delta_{min}(Y(\varepsilon))} = 0,
	\end{gather*}
	где $ \delta_{min}(Y(\varepsilon)) = \inf\limits_{\left\|y \right\| =1 } \delta(y|Y(\varepsilon))$, а $ \delta(y|Y(\varepsilon)) $ -- опорная функция множества $ Y(\varepsilon) $.
\end{theorem}
\subsubsection{Достаточное условие асимптотической эквивалентности множеств достижимости нелинейной и линеаризованной систем}
	Рассмотрим нелинейную систему, аффинную по управлению
\begin{gather}\label{nonlinearY}
	\begin{gathered}
		\dot{x}(t)=f_1(t,x(t))+f_2(t,x(t))u(t), \qquad t_0 \leq t \leq t_0 + \bar{\varepsilon}, \qquad x(t_0) = x_0, \\
		y(t) = C x(t).
	\end{gathered}
\end{gather}
Здесь $ x \in \mathbb{R}^n $ -- вектор состояния, $ u \in \mathbb{R}^r $ -- управление,  $ y\in\mathbb{R}^m (m \leqslant n) $ -- выход системы,
$ C\in \mathbb{R}^{m \times n} $  -- матрица полного ранга, $m\leq n$, $ \bar{\varepsilon} $ --- некоторое фиксированное положительное число.
	Как и в предыдущих разделах функции $ f_1: \mathbb{R}^{n+1} \rightarrow \mathbb{R}^{n} $, $ f_2: \mathbb{R}^{n+1} \rightarrow \mathbb{R}^{n \times r} $ предполагаются непрерывными и непрерывно-дифференцируемыми по $ x $.
По-прежнему предполагается, что функции $ f_1 $, $ f_2 $ удовлетворяют условиям
\begin{gather*}
	\begin{gathered}
		\left\| f_1(t,x) \right\| \leqslant	l_1(t)(1 + \left\| x \right\| ), \\
		\left\| f_2(t,x) \right\| \leqslant	l_2(t),  \qquad t_0 \leqslant t \leqslant t_0 + \bar{\varepsilon}, \qquad   x \in \mathbb{R}^n,
	\end{gathered}
\end{gather*}
где $ l_1(\cdot) \in \mathbb{L}_1[t_0,t_0+\bar{\varepsilon}] $, $ l_2(\cdot) \in \mathbb{L}_2[t_0,t_0+\bar{\varepsilon}] $. Предположение \ref{Pred} также считается выполненным.

 Управление $u(t)$ будем выбирать из
пространства $\mathbb{L}_2[t_0,t_0+\bar{\varepsilon}]$ вектор-функций и ограничим его шаром радиуса $ \mu > 0 $
\begin{gather}\label{constrY}
	\lVert u(\cdot)\rVert^2_{\mathbb{L}_2} = \left(u(\cdot),u(\cdot) \right) \leqslant \mu^2.
\end{gather}

В условиях описанных предположений, каждому $ u(\cdot) \in \mathbb{L}_2 $ соответствует единственное абсолютно непрерывное решение $ x(t)=x(t,u(\cdot)) $ системы \eqref{nonlinearY}, определённое на интервале $ [t_0,t_0+\bar{\varepsilon}] $.

Все траектории $ x(t) $ системы \eqref{nonlinearY}, отвечающие удовлетворяющим \eqref{constrY} управлениям,  лежат внутри некоторого компактного множества $ D \subset \mathbb{R}^n $. Пусть $ 0 <  \varepsilon \leqslant \bar{\varepsilon} $. 

Множеством достижимости системы \eqref{nonlinearY} по состоянию, как и прежде, будем называть множество \begin{gather*}
	G(\varepsilon)=\{x\in \mathbb{R}^n:\exists u(\cdot)\in B_{\mathbb{L}_2}(0,\mu),\; x=x(t_0+\varepsilon,x^0,u(\cdot))\}.
\end{gather*}


\begin{definition}
	{\textit Множеством достижимости $G_y(\varepsilon)$ системы \eqref{nonlinear} по выходу} $ y = C x $ будем называть множество всех выходов $ y(t_0+\varepsilon) $,
	соответствующих концам траекторий $ x(t_0+\varepsilon) $, порождённых управлениями $ u(t) \in B_{\mathbb{L}_2}(0,\mu)$
	\begin{gather*}
		G_y(\varepsilon)=\{y\in \mathbb{R}^m:\exists u(\cdot)\in B_{\mathbb{L}_2}(0,\mu),\; y=Cx(t_0+\varepsilon,x^0,u(\cdot))\}.
	\end{gather*}
\end{definition}

В определениях множеств, приведённых выше, можно считать, что $ \mathbb{L}_2 =\mathbb{L}_2[t_0,t_0+\varepsilon] $, либо  $ \mathbb{L}_2=\mathbb{L}_2[t_0,t_0+\bar{\varepsilon}] $. Нетрудно понять, что для любого из этих пространств мы получаем одно и то же множество достижимости. Будем далее считать, что $ \mathbb{L}_2 =\mathbb{L}_2[t_0,t_0+\varepsilon] $.
	
Заметим, что  $ G_y(\varepsilon) = C G(\varepsilon) $.	
	
Если матрица $ C \in \mathbb{R}^{m \times n} $ такова, что в каждой её строке только один элемент равен 1, а остальные равны 0, а в каждом столбце содержится не более одного ненулевого элемента, то $ y=Cx $ состоит из $ m$ координат вектора $ x $, а  множество достижимости $G_y(\varepsilon)$ представляет собой проекцию множества $ G(\varepsilon) $ на $m$--мерную координатную плоскость.


\begin{definition}
	Симметричная матрица, определённая равенством
	\begin{gather*}
		W_y(\varepsilon) = C\int_{t_0}^{t_0+\varepsilon}X(t_0+\varepsilon,t)B(t)B^{\top}(t)X^{\top}(t_0+\varepsilon,t) \, dtC^\top=CW(\varepsilon)C^\top,
	\end{gather*}
	называется грамианом управляемости системы \eqref{linear} на интервале времени $  t_0 \leq t \leq t_0 + \varepsilon $ по выходу $y$.
\end{definition}
	
	Система \eqref{linear} вполне управляема на  $ [t_0, t_0 + \varepsilon] $ по выходу $y=Cx$ тогда и только тогда,
	когда  грамиан управляемости по выходу $ \widetilde{W}_y(\varepsilon) = C \widetilde{W}(\varepsilon) C^{\top}  $ -- положительно определенная матрица, то есть его минимальное собственное число $ \nu^y(\varepsilon) $ положительно.
	
	Основной результат этого раздела отражен в следующей теореме.
	\begin{theorem}\label{th2}
		При достаточно малых $ \varepsilon $ множество достижимости $ G_y(\varepsilon) $ системы \eqref{nonlinear} по выходу $ y = C x $ выпукло и асимптотически эквивалентно множеству $W_y^{1/2}(\varepsilon)B_{\mathbb{R}^n}(0,\mu) + Cx(t_0+\varepsilon,0)$, если найдутся такие $ K>0 $, $ \alpha > 0 $, $ 0< \varepsilon_0<\overline{\varepsilon}  $, что для всех $ \varepsilon \leqslant \varepsilon_0 $
		\begin{gather}\label{cond1}
			\nu^y(\varepsilon) \geqslant \left\{ {\begin{array}{*{20}{l}}
					{K\varepsilon ^{3 - \alpha}, \mbox{\ если \ } f_2(t,x) \mbox{\ не зависит от \ } x}, \\
					{K\varepsilon ^{1 - \alpha}}, \mbox{\ в противном случае}.
			\end{array}} \right.
		\end{gather}
	\end{theorem}
	
	Здесь $W_y^{1/2}(\varepsilon)$ --- арифметический квадратных корень из матрицы $W_y(\varepsilon)$, $ B_{\mathbb{R}^n}(0,\mu) $ --- евклидов шар радиуса $ \mu $ в $ \mathbb{R}^n $
	
	\doc. 
	При фиксированном $ \varepsilon $ введем отображение $ F_{\varepsilon}: \mathbb{L}_2[0,1]  \rightarrow \mathbb{R}^n$, зависящее от параметра $ \varepsilon $ равенством $F_{\varepsilon}(\upsilon(\cdot)) = z(1,\upsilon(\cdot)) $, где  $ z(\tau,\upsilon(\cdot)) $ -- траектория системы \eqref{epsnonlinear}, соответствующая управлению $ \upsilon(\cdot) $. Тогда композиция отображений $ F_{\varepsilon}$ и $ C $, $ H_{\varepsilon}: \mathbb{L}_2[0,1]  \rightarrow \mathbb{R}^k $, есть $ H_{\varepsilon}(\upsilon(\cdot)) = CF_{\varepsilon}(\upsilon(\cdot)) = Cz(1,\upsilon(\cdot)) $. В силу \eqref{epscond}, мы имеем $ H_{\varepsilon}(B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))) = \widetilde{G}_y(\varepsilon) = G_y(\varepsilon)  $, где $ \varrho(\varepsilon) = \mu \sqrt{\varepsilon} $.
	
	Отображение $ H_{\varepsilon} $ непрерывно дифференцируемо по Фреше для $ \forall \upsilon(\cdot) \in  B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)) $, как композиция непрерывно дифференцируемых отображений и его производная Фреше $ H_{\varepsilon}': \mathbb{L}_2[0,1]  \rightarrow  \mathbb{R}^k $ определена равенством:
	\begin{gather*}
		H_{\varepsilon}'( \upsilon(\cdot))\delta \upsilon = C \delta z(1) = C F_{\varepsilon}'(\upsilon(\cdot))\delta  \upsilon,
	\end{gather*}
	где $ \delta z(1) $ --- решение линеаризованной системы \eqref{epslinear} c нулевыми начальными условиями и управлением $  \delta  \upsilon(\tau) $, $ F_{\varepsilon}'( \upsilon(\cdot)) $ --- производная Фреше отображения $ F _{\varepsilon}$.
	Для $ F_{\varepsilon}' $ имеет место равенство (см., например \footnote{Gusev M.I. Estimates of the minimal eigenvalue of the controllability Gramian for a system containing a small parameter//  Mathematical Optimization Theory and Operations Research. Lecture Notes in Computer Science. 2019. vol. 11548. P. 461--473.  https://doi.org/10.1007/978-3-030-22629-9\_32}).
	\begin{equation}\label{derivF}
		F_{\varepsilon}'( \upsilon(\cdot)) = X_{\varepsilon}(1,\tau, \upsilon(\cdot))B_{\varepsilon} (\tau, \upsilon(\cdot)), \quad \tau\in[0,1],
	\end{equation}
	где $ X_{\varepsilon}(1,\tau,\upsilon(\cdot)) $ --- фундаментальная матрицы системы \eqref{epslinear}, матрицы которой $ A_{\varepsilon}(\tau) $, $ B_{\varepsilon}(\tau)  $ зависят от $ \upsilon(\cdot) $.
	Из \eqref{derivF} следует, что $ H_{\varepsilon}'(u(\cdot)) $ есть ни что иное, как
	\begin{equation*}
		H_{\varepsilon}'(\upsilon(\cdot)) = C X_{\varepsilon}(1,\tau, \upsilon(\cdot))B_{\varepsilon} (\tau, \upsilon(\cdot)), \quad \tau\in[0,1],
	\end{equation*}
	Можно доказать, что $ F_{\varepsilon}'(\upsilon(\cdot)) $ --- липшицева
	\begin{equation}\label{lipdF}
		\left\| F_{\varepsilon}'(\upsilon_1(\cdot)) - F_{\varepsilon}'(\upsilon_2(\cdot)) \right\| \leqslant L(\varepsilon) \left\| \upsilon_1(\cdot) - \upsilon_2(\cdot)\right\|
	\end{equation}
	при $ \upsilon \in B_{\mathbb{L}_2[0,1]}(0,\rho(\varepsilon))  $, но тогда и $ H_{\varepsilon}'(\upsilon(\cdot)) $ --- липшицева. Доказательство проводится по схеме работы\footnote{Gusev M.I. The limits of applicability of the linearization method in calculating small-time reachable sets // Ural Mathematical Journal. 2020. Vol. 6, No. 1. P. 71-83 https://doi.org/10.15826/umj.2020.1.006}.  При этом $ L(\varepsilon) = L_0 + L_1 \varepsilon $, где $ L_0 = 0$, если $ f_2(t,x)  $ не зависит от $ x $.
	Тогда можно оценить максимальный радиус $ \rho(\varepsilon) $ гильбертова шара $ B_{\mathbb{L}_2[0,1]}(0,\rho(\varepsilon)) $, образ которого $ F_{\varepsilon}(B_{\mathbb{L}_2[0,1]}(0,\rho(\varepsilon))) $ будет выпуклым (см. \footnote{Polyak B.T. Сonvexity of the reachable set of nonlinear
		systems under l2 bounded controls // Dynamics of Continuous, Discrete and Impulsive Systems
		Series A: Mathematical Analysis. 2004. Vol. 11.  P. 255--267.}):
	\begin{equation}\label{Polest}
		\rho(\varepsilon) \leqslant \frac{\sqrt{\nu(\varepsilon)}}{2L(\varepsilon)}.
	\end{equation}
	Теперь проведем аналогичные рассуждения для $ H_{\varepsilon} $. Аналог неравенства \eqref{lipdF}  имеет вид
	\begin{equation*}
		\left\| H_{\varepsilon}'(\upsilon_1(\cdot)) - H'_{\varepsilon}(\upsilon_2(\cdot)) \right\| \leqslant L(\varepsilon) \left\| \upsilon_1(\cdot) - \upsilon_2(\cdot)\right\|,
	\end{equation*}
	где для константы Липшица $ L(\varepsilon) = L_0 + L_1 \varepsilon$ отображения $ H_{\varepsilon} $ сохраним то же обозначение, что и в \eqref{lipdF}.
	А неравенство \eqref{Polest} перепишем так, чтобы найти условие, при котором множество достижимости системы \eqref{epsnonlinear} по выходу $ \widetilde{G}_y(1) = H_{\varepsilon} (B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)))$ будет выпуклым:
	\begin{equation}\label{est2}
		4\varrho^2(\varepsilon)L^2(\varepsilon) = 4\mu^2\varepsilon L^2(\varepsilon) \leqslant \nu^y(\varepsilon),
	\end{equation}
	где $ \varrho(\varepsilon)  = \mu\sqrt{\varepsilon} $.
	
	В случае, если функция $ f_2(t,x) $ не зависит от $ x $, то $ L(\varepsilon) = L_1 \varepsilon  $, а \eqref{est2} принимает вид $ \nu^y(\varepsilon) \geqslant 4\mu^2L_1^2 \varepsilon^3 $.  Это неравенство будет выполнено, если $ K\varepsilon^{3 - \alpha} \geqslant 4\mu^2L_1^2 \varepsilon^3 $, что равносильно соотношению $ \varepsilon \geqslant \varepsilon_1 := \left(\frac{K}{4\mu^2L_1^2}\right)^{1/\alpha} $.  Таким образом, множество достижимости $ G_y(\varepsilon)$ выпукло при $ 0 \leqslant \varepsilon \leqslant \min\{\varepsilon_0,\varepsilon_1\}  $.  
	
	В другом случае, если $ f_2(t,x) $ зависит от $ x $, $ L(\varepsilon) =L_0+L_1\varepsilon $, а \eqref{est2} принимает вид $ \nu^y(\varepsilon) \geqslant 4\mu^2 \varepsilon (L_0 + L_1 \varepsilon)^2 $.  Учитывая, что $ \nu^y(\varepsilon)  \geqslant K \varepsilon^{1-\alpha} $, достаточно доказать, что $ K \varepsilon^{1-\alpha}  \geqslant 4\mu^2 \varepsilon (L_0 + L_1 \varepsilon_0)^2 $. Последнее неравенство выполняется при $ \varepsilon \leqslant \varepsilon_2 := \left(\frac{K}{4\mu^2(L_0 + L_1\varepsilon_0)^2} \right)^{1/\alpha} $. Следовательно, $ G_y(\varepsilon) $ выпукло, если $ 0 \leqslant \varepsilon \leqslant \min\{\varepsilon_0, \varepsilon_2\} $.
	
	Множество $ W_y^{1/2}(\varepsilon)B_{\mathbb{R}^n}(0,\mu) + Cx(t_0+\varepsilon,0)  = H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0)$ есть не что иное, как множество достижимости по выходу линеаризованной системы \eqref{epslinear}.
	
	Доказательство асимптотической эквивалентности проекций множеств достижимости нелинейной и линеаризованной систем проводится по той же схеме, что и доказательство следствий теоремы 2 в \footnote{Gusev M.I. The limits of applicability of the linearization method in calculating small-time reachable sets // Ural Mathematical Journal. 2020. Vol. 6, No. 1. P. 71-83 https://doi.org/10.15826/umj.2020.1.006}. Оценим сверху хаусдорфово расстояние между образами гильбертова шара $ H_{\varepsilon}\left( B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))\right)  $ и $ H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0) $:
	\begin{gather*}
		h\left( G_y(\varepsilon), H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0)\right)  \leqslant L(\varepsilon) \varrho^2(\varepsilon).
	\end{gather*}
	А так как $ \lim\limits_{\varepsilon \rightarrow 0}  L(\varepsilon) \varrho^2(\varepsilon) = 0 $, то и $ \lim\limits_{\varepsilon \rightarrow 0} h\left( G_y(\varepsilon), H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0)\right)  = 0 $.
	
	
	Множество достижимости линеаризованной системы -- конечномерный эллипсоид и его наименьшая полуось $ \delta_{min}\left(H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)) \right)=\varrho(\varepsilon)\sqrt{\nu^y(\varepsilon)} $. 
	Следовательно,
	\begin{gather*}
		\frac{h\left(G_y(\varepsilon), H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0)\right) }{\delta_{min}\left( H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))\right) } \leqslant \frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\nu^y(\varepsilon)}}.
	\end{gather*}
	
	При выполнении условий \eqref{cond1} в первом случае ($ f_2(t,x) $ не зависисит от $ x $) имеем
	\begin{gather*}
		\frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\nu^y(\varepsilon)}} 
		\leqslant
		\frac{L_1\varepsilon\mu\sqrt{\varepsilon}}{K^{\frac{1}{2}}\varepsilon^{\frac{3}{2}-\frac{\alpha}{2}}} 
		=
		L_1\mu K^{-\frac{1}{2}}\varepsilon^{\frac{\alpha}{2}} \rightarrow 0 \mbox{\ при\ } \varepsilon \rightarrow 0.
	\end{gather*}
	
	Во втором случае,
	\begin{equation*}
		\frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\nu^y(\varepsilon)}} 
		\leqslant
		\frac{(L_0+L_1\varepsilon)\mu\sqrt{\varepsilon}}{{K^{\frac{1}{2}}}\varepsilon^{\frac{1}{2}-\frac{\alpha}{2}}}
		=
		(L_0+L_1\varepsilon)\mu K^{-\frac{1}{2}}\varepsilon^{\alpha/2} \rightarrow 0 \mbox{\ при\ } \varepsilon \rightarrow 0.
	\end{equation*}
	
	Таким образом условия теоремы \ref{suff} выполнены, а значит множества $ G_y(\varepsilon) $ и \\ $ H'_{\varepsilon}(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0) $ асимптотически эквиваленты.
	\hfill $\square$
	\begin{utv}
		Пусть $ W_1 $, $ W $ -- симметричные матрицы, причем $ W_1 = C W C^{\top} $, где $ C $ -- матрица  полного ранга размерности $ m \times n $, $ m \leqslant n $, а $ \nu(W) $, $ \nu(W_1) $ и $ \nu(CC^{\top}) $ -- наименьшие собственные числа соответствующих матриц.
		
		Тогда
		\begin{gather*}
			\nu(W_1) \geqslant \nu(CC^{\top})  \nu(W).
		\end{gather*}
	\end{utv}
	\doc. 
	Действительно,
	\begin{gather*}
		\forall x \in \mathbb{R}^m, \: x^{\top} W_1 x = x^{\top} C W C^{\top} x \geqslant \nu(W)\left\| C^{\top}x \right\| ^2,\\
		\nu(W)\left\| C^{\top}x \right\| ^2 = \nu(W) x^{\top} C C^{\top} x
	\end{gather*}
	Следовательно,
	\begin{gather*}
		\nu(W_1) = \min \limits_{\left\| x\right\| =1}x^{\top}W_1x \geqslant \nu(W)\min \limits_{\left\| x\right\| =1}x^{\top}CC^{\top}x = \nu(CC^{\top})  \nu(W) 
	\end{gather*} \begin{flushright}
		\hfill $ \square $
	\end{flushright}
	
	Применяя утверждение к грамиану управляемости линеаризованной системы $ \widetilde{W}(\varepsilon) $, грамиану управляемости по выходу $ \widetilde{W}_y(\varepsilon) $, и их наименьшим собственным числам $ \nu^y(\varepsilon) $ и $ \nu(\varepsilon) $, получим
	\begin{equation*}
		\nu^y(\varepsilon) \geqslant \nu(CC^{\top}) \nu(\varepsilon),
	\end{equation*}
	где $ \nu(CC^{\top}) $ не зависит от $ \varepsilon $. Значит асимптотика $ \nu^y(\varepsilon) $ при $\varepsilon \rightarrow 0$ не может быть хуже асимптотики $ \nu(\varepsilon) $, если $ C $ -- матрица полного ранга. Это соответствует очевидному факту, если множество $ G(\varepsilon) $ -- выпуклое, то и для всех возможных матриц полного ранга $ C $, соответствующие множества $ {G}_y(\varepsilon) $ -- выпуклы. Однако невыпуклое множество $ G(\varepsilon) $  может иметь выпуклые проекции, что продемонстрировано в одном из примеров.
\subsubsection{О выпуклости двумерных проекций множеств достижимости уницикла на малых промежутках времени}	
	Исследуем проекции множеств достижимости на примере системы третьего порядка
	\begin{equation}\label{unicycle0}
		\dot{x_1} = v(t)\cos(x_3), \qquad
		\dot{x_2} = v(t)\sin(x_3), \qquad
		\dot{x_3} = u(t), \qquad 0 \leq t \leq \varepsilon
	\end{equation}
	при ограничениях на управление 
	\begin{gather*}
		v(t) = 1, \qquad \int_0^1 u^2(t) \, dt \leqslant 1
	\end{gather*}
	и нулевых начальных условиях $ x_1(0) = x_2(0) = x_3(0) = 0 $.
	
	Система \eqref{unicycle0} известна как уницикл (при $ v(t) = 1$  --- машина Дубинса). При геометрическом
	ограничении на
	управление ($|u(t)|\leq 1$) проекции множества достижимости  машины Дубинса  на двумерное пространство координат $(x_1,\,x_2)$ были исследованы в
	\footnote{Cockayne E.J., Hall G.W.C. Plane motion of a particle subject to curvature constraints // SIAM J. Control. 1975. Vol. 13, no. 1. P. 197--220.  https://doi.org/10.1137/0313012}. Общая трехмерная картина множества достижимости  получена в
	работе  \footnote{Пацко В.С., Пятко С.Г., Федотов А.А. Трехмерное множество достижимости нелинейной управляемой системы // Известия РАН. Теория и системы управления. 2003. № 3. С. 8--16}. Множество достижимости интегратора Брокетта, к которому нелинейными преобразованиями могут быть приведены уравнения уницикла \eqref{unicycle0}, исследовано в\footnote{Вдовин С.А., Тарасьев А.М., Ушаков В.Н., Построение множества достижимости интегратора Брокетта, Прикл. математика и механика, 68:5 (2004), 707-724}.
	
	Запишем решение $ x(t,u(t)) $, порожденное нулевым управлением $ u(t) \equiv 0 $:
	\begin{gather*}
		\begin{gathered}
			\dot{x_3} = 0 \longrightarrow x_3(t) = x_3(0) + 0 = 0, \\
			\dot{x_2} = \sin(x_3(t)) = \sin(0) \longrightarrow x_2(t) = x_2(0) + \int_0^t 0 \, d\tau = 0,\\
			\dot{x_1} = \cos(x_3(t)) = \cos(0) \longrightarrow x_3(t) = x_3(0) + \int_0^t	1 \, d\tau = t.
		\end{gathered}
	\end{gather*}
	Матрицы линеаризованной системы не зависят от $ t $ и имеют вид:
	\begin{equation}\label{linear0}
		A = \begin{pmatrix}
			0 & 0 & 0 \\ 
			0 & 0 & 1 \\ 
			0 & 0 & 0
		\end{pmatrix}, \qquad  B = \begin{pmatrix}
			0 \\ 
			0 \\ 
			1
		\end{pmatrix} 
	\end{equation}
	Пара $ (A,B) $, очевидно, не является вполне управляемой.
	Выпишем фундаментальную матрицу системы \eqref{linear0}, а затем получим грамиан управляемости линеаризованной системы
	\begin{gather*}
		\begin{gathered}
			\dot{X}(t,t_1) = A(t) X(t,t_1), \qquad X(t_1,t_1) = I \\
			X(t,\tau) = \begin{pmatrix}
				1 & 0 & 0 \\ 
				0 & 1 & \varepsilon \\ 
				0 & 0 & 1
			\end{pmatrix}  \\
			W(\varepsilon) = \int_0^{\varepsilon}X(\varepsilon,t) B B^{\top} X^{\top}(\varepsilon,t)dt 
			=\begin{pmatrix}
				0 & 0 & 0 \\
				0 & \frac{\varepsilon^3}{3} & \frac{\varepsilon^2}{2} \\
				0 &  \frac{\varepsilon^2}{2} & \varepsilon
			\end{pmatrix} 
		\end{gathered}
	\end{gather*}
	Сделаем замену времени и перепишем грамиан управляемости в виде
	\begin{gather*}
		\widetilde{W}(\varepsilon) = \frac{1}{\varepsilon}W(\varepsilon) 	=\begin{pmatrix}
			0 & 0 & 0 \\
			0 & \frac{\varepsilon^2}{3} & \frac{\varepsilon}{2} \\
			0 &  \frac{\varepsilon}{2} & 1
		\end{pmatrix} 
	\end{gather*} 
	Теперь последовательно рассмотрим проекции системы \eqref{unicycle0} на координатные плоскости $ (x_1, x_2) $, $ (x_1, x_3) $, $ (x_2, x_3) $. \\
	
	\begin{enumerate}
		\item Рассмотрим плоскость $ (x_1, x_2) $. Матрица $ C $ для этой проекции имеет вид
		\begin{gather*}
			C = \begin{pmatrix}
				1 & 0 & 0 \\
				0 & 1 & 0
			\end{pmatrix}.
		\end{gather*}
		Грамиан управляемости в нормированном времени
		\begin{gather*}
			\widetilde{W}_{x_1,x_2}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
				0 & 0 \\
				0 & \frac{\varepsilon^2}{3}. \\
			\end{pmatrix}.
		\end{gather*}
		Нетрудно заметить, что $ \widetilde{W}_{x_1,x_2}(\varepsilon) $ -- вырожденная. Следовательно, система \eqref{unicycle0} не управляема по выходу $ (x_1, x_2) $, а значит, достаточное условие выпуклости множества достижимости по выходу $ G_{x_1,x_2}(\varepsilon) $ не выполняется. Множество $ G_{x_1,x_2}(\varepsilon) $ полученное в численном эксперименте показано на рисунке~\ref{fig:RS}-\subref{fig:u=0_x1-x2}. Отметим, что в работе \footnote{Гусев М.И., Осипов И.О.
Асимптотическое поведение множеств достижимости на малых временных промежутках //
Труды Института математики и механики. 2019. Т.~25, № 3. С. 86--99.
https://doi.org/10.21538/0134-4889-2019-25-3-86-99} при помощи принципа максимума доказано, что $ G(\varepsilon) $ -- невыпукло. Из данного доказательства также следует, что $ G_{x_1,x_2}(\varepsilon) $ тоже не является выпуклой.
		
		В этой работе для построения множеств достижимости мы используем алгоритм, основанный на методе Монте-Карло. %\todo{тут  будет ссылка либо на статью Игоря, либо на раздел, когда он появится}\footnote{Zykof2}.
		Удовлетворяющее интегральным ограничениям управление $ u(t) $ представляется в виде линейной комбинации ортогональных полиномов. Коэффициенты этого разложения -- равномерно распределенные случайные нормированные векторы. Перебирая такие векторы, будем получать программные управления, удовлетворяющие ограничениям \eqref{constr}. Концы траекторий, порожденные такими управлениями, покрывают множество достижимости.
		
		
		\item Теперь рассмотрим проекцию на плоскость $ (x_1, x_3) $. Выпишем матрицы $ C $ и $ \widetilde{W}_{x_1,x_3}(\varepsilon) $
		\begin{gather*}
			C = \begin{pmatrix}
				1 & 0 & 0 \\
				0 & 0 & 1
			\end{pmatrix}, \qquad
			\widetilde{W}_{x_1,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
				0 & 0 \\
				0 & 1 \\
			\end{pmatrix} .
		\end{gather*}
		Ситуация аналогична предыдущему случаю: матрица $ \widetilde{W}_{x_1,x_3}(\varepsilon)  $ вырождена, достаточное условие выпуклости не выполняется. Результат численного моделирования приведен на рисунке~\ref{fig:RS}-\subref{fig:u=0_x1-x3}.
		\item Наконец, перейдем к плоскости $ (x_2, x_3) $. Здесь
		\begin{gather*}
			C = \begin{pmatrix}
				0 & 1 & 0 \\
				0 & 0 & 1
			\end{pmatrix}, \qquad \widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
				\frac{\varepsilon^2}{3} & \frac{\varepsilon}{2} \\
				\frac{\varepsilon}{2} & 1
			\end{pmatrix}.
		\end{gather*}
		В этом случае матрица $ \widetilde{W}_{x_2,x_3}(\varepsilon) $ не вырождена и ее минимальное собственное число $ \nu^{x_2,x_3} = \frac{\varepsilon^2}{12} + O(\varepsilon^4)  $ удовлетворяет критерию \eqref{cond1} при достаточно малых $ \varepsilon $ и множество достижимости по выходу $ G_{x_2,x_3}(\varepsilon) $, как следует из теоремы \ref{th2}, выпукло и асимптотически эквивалентно соответствующему множеству достижимости линеаризованной системы, что и проиллюстрировано на рисунке~\ref{fig:RS}-\subref{fig:u=0_x2-x3}. Пунктирной линией на рисунке показана точная граница множества достижимости линеаризованной системы, сдвинутая на $ Cx(\varepsilon, 0) $. Из рисунка видно, что эта граница (эллипс) практически совпадает с границей множества достижимости нелинейной системы.
	\end{enumerate} 
	
	\begin{figure}[ht!] 
		\hspace{-2.5ex}
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering 
			\includegraphics[width=\linewidth]{images/OsipovI_u=0_x1-x2.eps}
			%\input{OsipovI_u=0_x1-x2_0.tex}
			\subcaption{$ G_{x_1, x_2}(\varepsilon) $ системы \eqref{unicycle0};}
			\label{fig:u=0_x1-x2} 
		\end{minipage}
		\hfill
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering
			\includegraphics[width=\linewidth]{images/OsipovI_u=1_x1-x2.eps}
			%\input{OsipovI_u=1_x1-x2_0.tex}
			\subcaption{$ G_{x_1, x_2}(\varepsilon) $ системы \eqref{unicycle1};}
			\label{fig:u=1_x1-x2}  
		\end{minipage} 
		\vfill
		\hspace{-2.5ex}
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering 
			\includegraphics[width=\linewidth]{images/OsipovI_u=0_x1-x3.eps}
			%\input{OsipovI_u=0_x1-x3_0.tex}
			\subcaption{$ G_{x_1, x_3}(\varepsilon) $ системы \eqref{unicycle0};}
			\label{fig:u=0_x1-x3} 
		\end{minipage}
		\hfill
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering
			\includegraphics[width=\linewidth]{images/OsipovI_u=1_x1-x3.eps}
			%\input{OsipovI_u=1_x1-x3_0.tex}
			\subcaption{$ G_{x_1, x_3}(\varepsilon) $ системы \eqref{unicycle1};}
			\label{fig:u=1_x1-x3}  
		\end{minipage} 
		\vfill
		\hspace{-2.5ex}
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering 
			\includegraphics[width=\linewidth]{images/OsipovI_u=0_x2-x3.eps}
			%\input{OsipovI_u=0_x2-x3_0.tex}
			\subcaption{$ G_{x_2, x_3}(\varepsilon) $ системы \eqref{unicycle0};}
			\label{fig:u=0_x2-x3} 
		\end{minipage}
		\hfill
		\begin{minipage}[b]{.49\linewidth} 
			\small
			\centering
			\includegraphics[width=\linewidth]{images/OsipovI_u=1_x2-x3.eps}
			%\input{OsipovI_u=1_x2-x3_0.tex}
			\subcaption{$ G_{x_2, x_3}(\varepsilon) $ системы \eqref{unicycle1};}
			\label{fig:u=1_x2-x3}  
		\end{minipage}
		\caption{Результаты численного эксперимента для $ \varepsilon = 0.01 $.}\label{fig:RS}
	\end{figure}
	
	Немного изменим рассмотренный пример для того, чтобы линеаризованная система оставалась управляемой. Итак, рассматривается нелинейная система
	\begin{equation}\label{unicycle1}
		\dot{x_1} = \cos(x_3), \qquad
		\dot{x_2} = \sin(x_3), \qquad
		\dot{x_3} = 1 + u(t), \qquad 0 \leq t \leq \varepsilon
	\end{equation}
	при интегральных ограничениях на управление 
	\begin{equation*}
		\int_0^1 u^2(t) dt \leqslant 1
	\end{equation*}
	и нулевых начальных условиях $ x_1(0) = x_2(0) = x_3(0) = 0 $. Фактически, это то же самое, что рассматривать исходную систему при ограничении $ \displaystyle{\int_0^1} \left( u(t) - 1\right)^2 \ dt \leqslant 1$.
	
	Порождённое нулевым управлением $ u(t) \equiv 0 $ решение обозначим $ x(t,0) = x(t) $ и будем использовать его как опорное. 
	\begin{gather}\label{trj}
		\begin{gathered}
			\dot{x_3} = 1 \longrightarrow x_3(t) = x_3(0) + t = t, \\
			\dot{x_2} = \sin(x_3(t)) = \sin(t) \longrightarrow x_2(t) = x_2(0) + \int_0^t \sin(\tau) d\tau = 1 - \cos(t),\\
			\dot{x_1} = \cos(x_3(t)) = \cos(t) \longrightarrow x_1(t) = x_1(0) + \int_0^t \cos(\tau) d\tau = \sin(t).
		\end{gathered}
	\end{gather}
	Выпишем матрицы линеаризованной вдоль траектории \eqref{trj} системы 
	\begin{gather*}
		A(t) = \begin{pmatrix}
			0 & 0 & -\sin(t) \\ 
			0 & 0 & \cos(t) \\ 
			0 & 0 & 0
		\end{pmatrix}, \qquad  B = \begin{pmatrix}
			0 \\ 
			0 \\ 
			1
		\end{pmatrix}.
	\end{gather*}
	Для изучения грамиана управляемости выпишем фундаментальную матрицу линеаризованной системы
	\begin{gather*}
		\begin{gathered}
			X(t,\tau) = \begin{pmatrix}
				1 & 0 & \cos(t)-\cos(t_1) \\ 
				0 & 1 & \sin(t)-\sin(t_1) \\ 
				0 & 0 & 1
			\end{pmatrix}.
		\end{gathered}	
	\end{gather*}
	Грамиан управляемости имеет вид
	\begin{gather*}
		W(\varepsilon) = \int_0^{\varepsilon}X(\varepsilon,t) B B^{\top} X^{\top}(\varepsilon,t)dt =
	\end{gather*}
	\begin{gather*}
		=\begin{pmatrix}
			\varepsilon-\dfrac{3}{4} \sin(2\varepsilon) +\dfrac{1}{2}\varepsilon \cos(2\varepsilon)& \dfrac{3}{2}\cos^2(\varepsilon) - \cos(\varepsilon) + \dfrac{1}{2}\varepsilon \sin(2 \varepsilon) - \dfrac{1}{2} &  \varepsilon\cos( \varepsilon)-\sin( \varepsilon) \\[8pt] 
			* & \dfrac{3}{4}\sin(2\varepsilon) + \dfrac{1}{2}\varepsilon + \varepsilon \sin^2(\varepsilon) - 2 \sin(\varepsilon) & \cos(\varepsilon) + \varepsilon\sin(\varepsilon)-1 \\ 
			* & * & \varepsilon
		\end{pmatrix}.	
	\end{gather*}
	Здесь и далее, будем заменять элементы симметричных матриц под главной диагональю на $ * $ для лаконичной записи.
	Проделаем замену времени $ t = \varepsilon \tau $ и выпишем грамиан управляемости $ \widetilde{W}(\varepsilon) $ линеаризованной системы в новом времени $ \tau $
	\begin{gather*}
		\widetilde{W}(\varepsilon) = \dfrac{1}{\varepsilon} W(\varepsilon) = 
	\end{gather*} \footnotesize
	\begin{gather*}
		=\begin{pmatrix} 
			\cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
			\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)+\dfrac{1}{2\,\varepsilon}\left( 3\cos^2\left(\varepsilon \right)-2\cos\left(\varepsilon\right)-1\right) &
			\cos\left(\varepsilon \right)-\dfrac{1}{\varepsilon} \sin\left(\varepsilon \right) \\[8pt] 
			* &
			\dfrac{3}{2}-\dfrac{2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2}}{\varepsilon }-{\cos\left(\varepsilon \right)}^2 & \sin\left(\varepsilon \right)+\dfrac{1}{\varepsilon } \left(\cos\left(\varepsilon \right)-1 \right)\\
			* &
			* & 
			1 \end{pmatrix}.	
	\end{gather*}
	\normalsize
	Далее последовательно рассмотрим проекции системы \eqref{unicycle1} на координатные плоскости $ (x_1, x_2) $, $ (x_1, x_3) $, $ (x_2, x_3) $. \\
	
	\begin{enumerate}
		\item Будем рассматривать проекцию $ G_{x_1, x_2}(\varepsilon) $ области достижимости системы \eqref{unicycle1} на плоскость первых двух фазовых координат. Матрица проектирования будет иметь вид
		\begin{equation*}
			C = \begin{pmatrix}
				1 & 0 & 0 \\ 
				0 & 1 & 0 
			\end{pmatrix}. 
		\end{equation*} 
		Тогда: \small
		\begin{equation}\label{Ve}
			\widetilde{W}_{x_1,x_2}(\varepsilon)= \begin{pmatrix}
				\cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
				\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)+\dfrac{1}{2\,\varepsilon}\left( 3\cos^2\left(\varepsilon \right)-2\cos\left(\varepsilon\right)-1\right) \\[6pt]
				* &
				\dfrac{3}{2}-\dfrac{1}{\varepsilon }\left(2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2} \right) -{\cos\left(\varepsilon \right)}^2 
			\end{pmatrix}
		\end{equation}
		\normalsize
		Для исследования асимптотики $ \nu^{x_1,x_2}(\varepsilon) $ -- минимального собственного числа $ \widetilde{W}_{x_1,x_2}(\varepsilon) $, перепишем \eqref{Ve}, разложив тригонометрические функции в ряд вблизи точки $ \varepsilon = 0 $.
		\begin{gather*}
			\widetilde{W}_{x_1,x_2}(\varepsilon) = \begin{pmatrix}
				\dfrac{2\,\varepsilon ^4}{15} + O(\varepsilon^6)&
				-\dfrac{5\,\varepsilon ^3}{24} + O(\varepsilon^5)\\[8pt]
				-\dfrac{5\,\varepsilon ^3}{24} + O(\varepsilon^5) & 
				\dfrac{\varepsilon ^2}{3}-\dfrac{3\,\varepsilon ^4}{20} + O(\varepsilon^6).
			\end{pmatrix}.
		\end{gather*}
		
		Минимальное собственное число $ \nu^{x_1,x_2}(\varepsilon) = \frac{1}{120}\varepsilon^4 + O(\varepsilon^6)$, а $ \varepsilon^4 < \varepsilon^{3-\alpha} $ для всех $ \alpha > 0 $ при достаточно малых $ \varepsilon $, то есть достаточное условие выпуклости $ G_{x_1, x_1}(\varepsilon) $ не выполняется. Результаты численного моделирования, приведённые на рисунке~\ref{fig:RS}-\subref{fig:u=1_x1-x2}, показывают невыпуклость проекции. 
		\item Перейдем к плоскости $ (x_1,x_3) $. 
		\begin{gather*}
			C = \begin{pmatrix}
				1 & 0 & 0 \\
				0 & 0 & 1
			\end{pmatrix}, \qquad
			\widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  = \\ =\begin{pmatrix}
				\cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
				\cos\left(\varepsilon \right)-\dfrac{1}{\varepsilon} \sin\left(\varepsilon \right) \\ 
				* & 1
			\end{pmatrix}.
		\end{gather*}
		Так же, как и в случае плоскости $ (x_1,x_2) $ разложим компоненты $ 	\widetilde{W}_{x_1,x_3}(\varepsilon)  $ в ряд вблизи точки $ \varepsilon = 0 $:
		\begin{gather*}
			\widetilde{W}_{x_1,x_3}(\varepsilon) = \begin{pmatrix} 
				\dfrac{2\,\varepsilon ^4}{15} + O(\varepsilon^6) &
				-\dfrac{\varepsilon^2}{3}+ O(\varepsilon ^4)\\[8pt]
				-\dfrac{\varepsilon^2}{3} + O(\varepsilon^4) & 1 \end{pmatrix}.
		\end{gather*}
		Минимальное собственное число матрицы $  \widetilde{W}_{x_1,x_3}(\varepsilon)  $, $ \nu^{x_1,x_3} =   \frac{1}{45}\varepsilon^4 + O(\varepsilon^6) $, также не удовлетворяет условию \eqref{cond1}. Соответствующий результат численного построения проекции множества достижимости показан на рисунке~\ref{fig:RS}-\subref{fig:u=1_x1-x3}.
		\item Последний случай -- плоскость $ (x_2,x_3) $.
		\begin{gather*}
			C = \begin{pmatrix}
				0 & 1 & 0 \\
				0 & 0 & 1
			\end{pmatrix}, \qquad
			\widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\\=\begin{pmatrix}
				\dfrac{3}{2}-\dfrac{2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2}}{\varepsilon }-{\cos\left(\varepsilon \right)}^2 & \sin\left(\varepsilon \right)+\dfrac{1}{\varepsilon } \left(\cos\left(\varepsilon \right)-1 \right)\\[8pt]
				* & 
				1 
			\end{pmatrix}.
		\end{gather*}
		Точно также разложим $ \widetilde{W}_{x_2,x_3}(\varepsilon) $ в ряд
		\begin{gather*}
			\widetilde{W}_{x_2,x_3}(\varepsilon)  = \begin{pmatrix}
				\dfrac{\varepsilon^2}{3} + O(\varepsilon^4) &
				\dfrac{\varepsilon }{2} + O(\varepsilon^3) \\[8pt]
				\dfrac{\varepsilon }{2} + O(\varepsilon^3) & 1
			\end{pmatrix}
		\end{gather*}
		Минимальное собственное число в этом случае равно $ \nu^{x_2,x_3}(\varepsilon) = \frac{\varepsilon^2}{12} + O(\varepsilon^4) $, то есть удовлетворяет условию \eqref{cond1}. Выпуклость этой проекции проиллюстрирована на рисунке~\ref{fig:RS}-\subref{fig:u=1_x2-x3}.  Как и на рисунке~\ref{fig:RS}-\subref{fig:u=0_x2-x3}, здесь пунктирной линией показана точная граница множества достижимости линеаризованной системы.
	\end{enumerate}
\subsection{Условие применимости метода линеаризации в задаче локального синтеза} 
We consider the problem of a feedback control design for a nonlinear control-affine system. The aim of the control is to bring  trajectories of the closed system to the origin of coordinates in a given time, providing the minimal value of an integral functional. The object under study is the nonlinear system, closed by a linear feedback controller. The controller is  obtained as a solution of the LQR problem for the linearized system. We indicate sufficient conditions  for this linear feedback to give a local solution to the control synthesis problem under consideration.  In addition, we give some  error estimates for the values of the functional. 

\subsection{Introduction}

We propose here a method for solving the problem of a local control synthesis  for a control-affine system on a small time interval. This method is based  on the linearization of the original nonlinear system in the vicinity  of the equilibrium position.  Linearization is often used in solving various control problems, such as stabilization problems\cite{Kras,halil}, stochastic and numerical control\cite{Roxin,EKF,denBerg,Pang}, MPC control\cite{Murillo,LTV_MPC}, etc.

In this article, we study the problem of control synthesis with an integral quadratic cost. Note that the task is considered on a finite, and, moreover, small, time interval. The goal of the control is to transfer the system to the origin in a given time ensuring the minimum value of the cost. The linear feedback control found for the linearized system is used as  the input of the original non-linear system. For a linear control system the optimal feedback is linear in state, with gains increasing indefinitely when approaching the terminal time. The latter  makes it difficult to justify the applicability of the linearization method. The restrictions on  asymptotics  of the controllability Gramian of the linearized system are needed in this case. Unlike, for example, the stabilization problem for which controllability (stabilizability) of the linearized system implies stabilizability of the nonlinear system. These restrictions coincide with the  asymptotic equivalence conditions for reachable  (null-controllable) sets of nonlinear and linearized systems. In \cite{GusevOsipov} it was shown that, under these conditions the control in the form of a linear state feedback takes all trajectories starting from some neighborhood of zero to zero, if the control time interval is sufficiently small. 

In this article, we generalize the main result of \cite{GusevOsipov}. The proposed sufficient conditions have the form of an inequality for some improper integral. They depend on the smallest and the largest eigenvalues of the controllability Gramian of the linearized system and contain a scalar parameter. The choice of this parameter makes it possible to cover a wider class of control systems, the conditions from \cite{GusevOsipov} are obtained here as a special case for a certain value of the parameter.

For a linearized system, the considered linear controller delivers the minimum value to the integral functional for any initial state. For a nonlinear system, this is not the case, so it is important to obtain an estimate of the resulting error. This was done in the second part of the article, where  the relation between the values of the integral cost for the trajectories of the nonlinear and linearized systems was studied and  the estimate for the relative error was given. 

The article is structured as follows. The problem statement and some preliminary results are given in the second section. The third section contains the formulation and proof of the main results. Finally, we provide two illustrative examples in the fourth section.

\subsection{Preliminary results}
\subsubsection{Problem statement}

Let us consider the nonlinear  control-affine system
\begin{gather}\label{nonlinear}
	\dot{z}(t)=f(z(t))+B u(t),\qquad 0 \leqslant t \leqslant T, \qquad z(0) = z_0.
\end{gather}
 where $ x \in \mathbb{R}^n $ is a state vector, $ u \in \mathbb{R}^r $ is a control vector,  $ 
T$ is a positive number. We postulate that the function $f$ has the following property. 
\begin{property}\label{prop:Residial_term_bounds}
	 There exist  $r>0$, $k>0$  such that for all $ z \in B(0,r) $ the function $f(z)$ could be rewritten in the form $ f(z) = Az + R(z) $, where  $ \|R(z) \| \leqslant k \| z\|^2  $. 
\end{property}
Here $ B(0,r) $ is the ball of radius $r$  centered at $0 \in \mathbb{R}^n$. 
This property holds if $f(0) = 0 $, $\frac{\partial f}{\partial x}(0) 
= A $ and $f(z)$ is twice differentiable. 

The space of square integrable scalar or vector functions on $ [0,T] $ we will denote by $ \mathbb{L}_2 = \mathbb{L}_2[0,T] $. The ball in the space $\mathbb{L}_2$ we denote as $B_{\mathbb{L}_2}(0,r)$. As the cost functional we consider the following
\begin{gather}\label{cost}
		I(T,u):=\int_0^Tu^\top (t)u(t)dt= 	\lVert u(\cdot)\rVert^2_{\mathbb{L}_2.} 
\end{gather}
The problem is to synthesize a feedback control $u(t)=u(t,z(t))$ that leads the trajectories of the closed system 
\begin{gather*}
	\dot{z}(t)=f(z(t))+B u(t,z(t)),\qquad 0 \leqslant t \leqslant T, \qquad z(0) = z_0.
\end{gather*}
to the origin of coordinates at  time $T$ and to provide the minimum value of $I(T,u)$. 

Consider the linear case ($R(z)=0$)
\begin{gather}\label{linear}
	\dot{z} =  A  z + B u, \qquad 0 \leqslant t \leqslant T.
\end{gather}
If  system (\ref{linear}) is controllable the solution of the above problem  is the linear in state feedback controller 
\begin{gather}\label{linear_feedback}
	u(t,z) = -B^{\top} Q_T(t) z
\end{gather}
(see, for example, \cite{Abgar,Kur1,GusevOsipov}).
Here $Q_T(t)=W^{-1}(T-t)$ where $W(t)$ is the Controllability Gramian of system $\dot{x} = -A x - B u$:
\begin{gather*}
    W(t) = \int_0^t e^{-A\tau}BB^\top e^{-A^{\top}\tau}d\tau. 
\end{gather*}
The Gramian $W(t)$ is positive definite for $t>0$ iff  
system (\ref{linear}) is controllable. It may be shown that $Q_T(t)$ is the solution of differential equation 
\begin{gather}\label{eqQ}
	\dot{Q_T}  = Q_T B B^{\top} Q_T - A^{\top}Q_T - Q_T A, \quad Q_T(0)=W^{-1}(T).
\end{gather}
Thus, to find $Q_T(t)$ on  $(0,T]$ one need first to calculate $W(T)$ and then integrate the system (\ref{eqQ}).
Since $W(0)=0$, $Q_T(t)$ is determined for $t<T$ and 
$\|Q_T(t)\| \to \infty$ as $t\to T$. 

The following is true \cite{Abgar,Kur1,GusevOsipov}.
\begin{utv}
Any trajectory $z(t)$ of the system \eqref{linear} with the control \eqref{linear_feedback} starting from the point $ z_0 $ reaches the origin at time $T$. The  integral cost $I(T,u)$ takes the minimum possible value $z^{\top}_0 Q_T(0) z_0 $ for each $z_0$.
\end{utv}
Further we are going to investigate the trajectories behavior of system \eqref{nonlinear} closed by linear feedback $ u(t,z) = -B^{\top} Q_T(t) z$
assuming that $T$ is  small enough. Is it true that all trajectories starting in some neighborhood of the origin reach  it? And what is the value of the cost functional? 

\subsubsection{Asymptotic equality of reachable sets}

In what follows, we use a notion of an asymptotic equality of reachable sets. Consider a control system whose equations are obtained from \eqref{nonlinear} by time reversal. Setting $\tau=T-t$ we have
\begin{gather}\label{nonlinear_}
			\dot{x}(\tau)=-f(x(\tau))-B v(\tau),\qquad 0 \leqslant \tau \leqslant T; 
\end{gather}
here $x(\tau)=z(T-\tau)$, $v(\tau)=u(T-\tau)$.
For a given $\mu>0$ denote as $ G_{-} (T,\mu)$ a reachable set of the system \eqref{nonlinear_} under quadratic integral constraints on the cost functional, $G_{-}(T,\mu)=\{x\in \mathbb{R}^n:\exists v(\cdot)\in B_{\mathbb{L}_2}(0,\mu),\; x=x( T,v(\cdot)))\}$.
		 
Here $x( \tau,v(\cdot)))$ denotes the solution of \eqref{nonlinear_} with zero initial state. Properties of reachable sets of nonlinear systems with integral constraints on control have been studied in many papers (see, for example \cite{Guseinov,Rousse,GusZykIFAC}).
Consider also the linear system 
\begin{gather}\label{linear_}
			\dot{x}(\tau)=-Ax(\tau)-B v(\tau),\qquad 0 \leqslant \tau \leqslant T; 
\end{gather}
this system is the linearization of  the system \eqref{nonlinear_} at the origin. It's reachable set we denote by $G_{-}^0(T,\mu)$. This set is an ellipsoid in $\mathbb{R}^n$ described by inequality $G_{-}^0(T,\mu)=\{x \in \mathbb{R}^n: x^\top W^{-1}(T)x\leqslant \mu^2\} $.			

Let $X,Y \subset \mathbb R^n $ be convex compact sets such that the origin is an interior point of both the sets.
\begin{definition}[see, for example, \cite{Lassak,Ovs}]
The Banach-Mazur distance between $X$ and $Y$  is defined as
$\rho(X,Y):=\log\big(r(X,Y)\cdot r(Y,X)\big)$, where \\ $r(X,Y)=\inf \{t\geqslant1:tX \supset Y\}$. 
\end{definition} 
From the definition it follows that for any $c>0$, $\rho(cX,cY)=\rho(X,Y)$ and two inclusions are valid: $X\subset \exp(\rho(X,Y))Y$ and $Y\subset \exp(\rho(X,Y))X$.

Assume that  $X,Y$ depend on a small positive parameter $\tau$,  $0<\tau\leqslant\tau_0$  and set-valued mappings  $X(\tau), Y(\tau)$ are bounded. 
\begin{definition}[\cite{Ovs}]	
 The sets $ X (\tau), Y (\tau) $ are called asymptotically equal under $\tau \to 0$ if $ \rho (X (\tau), Y (\tau)) \to 0,\;\; \tau \to 0$.
\end{definition}
Denote by $\nu(\tau), \eta(\tau)$  the smallest and the largest eigenvalues of $W(\tau)$ respectively. From  the results of  \cite{Polyak_paper,GusOs,Osipov,GusevMotor} it follows that the reachable sets 
$G_{-}(\tau,\mu)$ and $G_{-}^0(\tau,\mu)$ are asymptotically equal under $\tau \to 0$ if the pair $(A,B)$ is controllable and
there exist $ l > 0$, $\tau_0 > 0$ and $\alpha > 0$ such that for any $0 < \tau \leqslant \tau_0 $
		\begin{gather}\label{gramas}
			\nu(\tau)\geqslant l\tau^{4-\alpha}.
		\end{gather}

\begin{zam}
    The reachable set $G_{-}(T,\mu)$ of system \eqref{nonlinear_} coincides with the null-controllable set of system \eqref{nonlinear}, i.e. the set of initial conditions from which the system can be led to the origin by controls from $B_{\mathbb{L}_2}(0,\mu) $ at time T. The same is true for systems \eqref{linear_} and \eqref{linear_} and their corresponding set $G_{-}^0(T,\mu)$.
\end{zam}

\end{document}